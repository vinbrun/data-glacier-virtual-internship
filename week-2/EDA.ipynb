{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f72b8ec9-bf06-4f44-bde8-fe2f9d804e8e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Cab Investment Project, by Vinicius Brun, 2024\n",
    "\n",
    "## What is the business problem?\n",
    "    The business problem is to determine the best cab company for investment: pink company vs yellow company. \n",
    "    To do that, I research for references about techniques to compare two companies and found Ratio Analysis (Chen, 2023). These are a series of quantitaive indicators used by investor to compare companies. Not all of them can be used with our data, but some of them can:\n",
    "    - Net Profit Margin = Net Profit ‚ÅÑ Total Revenue x 100\n",
    "    - Operating Margin Ratio = Net Operating Income / Total Revenue \n",
    "    [Net Operating Income = Gross Income - Operating Expenses]\n",
    "\n",
    "    Other ratios that could be calculated with more financial data are: Price-to-Earnings Ratio, Return on Assets Ratio and Return on Equity Ratio. \n",
    "\n",
    "    Another important analysis is about the taxi market. Recently ride share apps have become proeminent worldwide, but data indicates that the cab market remains strong (Statista, 2024). Research indicates that these two categories appeal to different customers.\n",
    "    \"Young people may be gravitating towards ride-sourcing because it presents a cost advantage over conventional taxis and is much more convenient in terms of service delivery. However, their use of ride-hailing services does not seem to be significant enough for it to be a threat to conventional taxis since few reported using their apps as their primary mode of transport or with high regularity (less than 2 weeks). Respondents tended to use ride-sourcing services for trips which were more social and were more likely to use them on trips during weekends, further demonstrating its limited use\" (Dzisi et al., 2020).\n",
    "\n",
    "    This indicates that, even though lyft apps have gained stagering proporitons, taxi companies are still relevant for investment. \n",
    "    \n",
    "    In this exercise, we used data from 2016 to 2018, before the COIVD-19 outbreak, so we will not be considering the pandemic in the analysis. \n",
    "    \n",
    "## References:\n",
    "Chen, J. (2023, March 23). How does ratio analysis make it easier to compare different companies? Investopedia. https://www.investopedia.com/ask/answers/032315/how-does-ratio-analysis-make-it-easier-compare-different-companies.asp\n",
    "Dzisi, E. K., Ackaah, W., Aprimah, B. A., & Adjei, E. (2020). Understanding demographics of ride-sourcing and the factors that underlie its use among young people. Scientific African, 7, e00288. https://doi.org/10.1016/j.sciaf.2020.e00288\n",
    "Meng, Chuan & Kaiyrbayeva, Ainur. (2024). FACTORS INFLUENCING THE DECISION TO INVEST. Izdenister natigeler. 566-572. 10.37884/2-2024/55.\n",
    "Statista. (2024). Taxi - United States | Statista Market Forecast.https://www.statista.com/outlook/mmo/shared-mobility/taxi/united-states#revenue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c20c76-7d12-4176-b69f-920f204255c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import files\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "cab_data = pd.read_csv(\"DataSets/Cab_Data.csv\")\n",
    "transaction_data = pd.read_csv(\"DataSets/Transaction_ID.csv\")\n",
    "customer_data = pd.read_csv(\"DataSets/Customer_ID.csv\")\n",
    "city_data = pd.read_csv(\"DataSets/City.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0839fe8-2d40-4bbb-b5e5-ab7ca745ab57",
   "metadata": {},
   "source": [
    "# Field names and data types\n",
    "\n",
    "### Cab_Data.csv\n",
    "- Transaction_ID: int\n",
    "- Date_of_Travel: str (or int if it's an encoded date)\n",
    "- Company: str\n",
    "- City: str\n",
    "- KM Travelled: float\n",
    "- Price Charged: float\n",
    "- Cost of Trip: float\n",
    "\n",
    "### City.csv\n",
    "- City: str\n",
    "- Population: int\n",
    "- Users: int\n",
    "\n",
    "### Customer_ID.csv\n",
    "- Customer_ID: int\n",
    "- Gender: str\n",
    "- Age: int\n",
    "- Income (USD/Month): float\n",
    "\n",
    "### Transaction_ID.csv\n",
    "- Transaction_ID: int\n",
    "- Customer_ID: int\n",
    "- Payment_Mode: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46cd3a-300c-41a0-922d-e773d5eea4c0",
   "metadata": {},
   "source": [
    "# Deduplication approach (from Data Intake Report)\n",
    "\n",
    "o\tIdentify exact duplicates based on the column Transaction_ID in the file Transaction_ID.csv (unique identifier).\n",
    "o\tIdentify exact duplicates based on the column Customer_ID in the file Customer_ID.csv (unique identifier).\n",
    "o\tIdentify exact duplicates based on the column Transaction_ID in the file Cab_Data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c44b55a0-abed-4237-be72-e78222c5abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed from Transaction_ID.csv: 0\n",
      "Duplicates removed from Customer_ID.csv: 0\n",
      "Duplicates removed from Cab_Data.csv: 0\n"
     ]
    }
   ],
   "source": [
    "# Data Deduplication\n",
    "\n",
    "# Transaction_ID.csv\n",
    "# Drop exact duplicates based on Transaction_ID\n",
    "transaction_data_deduped = transaction_data.drop_duplicates(subset=\"Transaction ID\")\n",
    "print(\"Duplicates removed from Transaction_ID.csv:\", len(transaction_data) - len(transaction_data_deduped))\n",
    "\n",
    "# 2. Deduplicate Customer_ID.csv\n",
    "# Drop exact duplicates based on Customer_ID\n",
    "customer_data_deduped = customer_data.drop_duplicates(subset=\"Customer ID\")\n",
    "print(\"Duplicates removed from Customer_ID.csv:\", len(customer_data) - len(customer_data_deduped))\n",
    "\n",
    "# 3. Deduplicate Cab_Data.csv\n",
    "# Drop duplicates based on columns that define a unique trip\n",
    "cab_data_deduped = cab_data.drop_duplicates(subset=\"Transaction ID\")\n",
    "print(\"Duplicates removed from Cab_Data.csv:\", len(cab_data) - len(cab_data_deduped))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc325ddc-d19f-47b3-bbb8-c18af1d0cfe4",
   "metadata": {},
   "source": [
    "# Data validation approach (from Data Intake Report)\n",
    "\n",
    "o\tJoin Cab_Data.csv with Transaction_ID.csv on Transaction_ID to ensure that each trip in Cab_Data.csv has a corresponding transaction in Transactoin_ID.csv. \n",
    "o\tJoin Transaction_ID.csv with Customer_ID.csv on Customer_ID to ensure that transaction in Transactoin_ID.csv has a corresponding customer in Customer_ID.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c9ebfe6-a1b2-400e-853b-706a5ccb12d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trips in Cab_Data.csv without corresponding transaction in Transaction_ID.csv: 0\n",
      "Transactions in Transaction_ID.csv without corresponding customer in Customer_ID.csv: 0\n"
     ]
    }
   ],
   "source": [
    "# Data Validation\n",
    "\n",
    "# Validate that each trip in Cab_Data.csv has a corresponding transaction in Transaction_ID.csv\n",
    "\n",
    "# Merge Cab_Data.csv with Transaction_ID.csv on Transaction_ID\n",
    "cab_transaction_merged = cab_data_deduped.merge(transaction_data_deduped, on=\"Transaction ID\", how=\"left\", indicator=True)\n",
    "\n",
    "# Check for any trips in Cab_Data.csv without a matching transaction\n",
    "missing_transactions = cab_transaction_merged[cab_transaction_merged[\"_merge\"] == \"left_only\"]\n",
    "print(\"Trips in Cab_Data.csv without corresponding transaction in Transaction_ID.csv:\", len(missing_transactions))\n",
    "\n",
    "# Remove the _merge column\n",
    "cab_transaction_merged = cab_transaction_merged.drop(columns=\"_merge\")\n",
    "\n",
    "# Display any missing transactions\n",
    "if not missing_transactions.empty:\n",
    "    print(\"Trips missing in Transaction_ID.csv:\")\n",
    "    print(missing_transactions)\n",
    "\n",
    "# Step 2: Validate that each transaction in Transaction_ID.csv has a corresponding customer in Customer_ID.csv\n",
    "\n",
    "# Merge Transaction_ID.csv with Customer_ID.csv on Customer_ID\n",
    "transaction_customer_merged = transaction_data_deduped.merge(customer_data_deduped, on=\"Customer ID\", how=\"left\", indicator=True)\n",
    "\n",
    "# Check for any transactions without a matching customer\n",
    "missing_customers = transaction_customer_merged[transaction_customer_merged[\"_merge\"] == \"left_only\"]\n",
    "print(\"Transactions in Transaction_ID.csv without corresponding customer in Customer_ID.csv:\", len(missing_customers))\n",
    "\n",
    "# Remove the _merge column\n",
    "transaction_customer_merged = transaction_customer_merged.drop(columns=\"_merge\")\n",
    "\n",
    "# Display any missing customers (optional)\n",
    "if not missing_customers.empty:\n",
    "    print(\"Transactions missing in Customer_ID.csv:\")\n",
    "    print(missing_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab44d86e-4a22-488e-bf67-083f104b2924",
   "metadata": {},
   "source": [
    "# Relationships across the files and determine which should be joined or appended\n",
    "\n",
    "## Cab_Data.csv and Transaction_ID.csv\n",
    "- Relationship: One-to-One\n",
    "- Transaction_ID is the primary key in both files. We can join these two files on Transaction_ID.\n",
    "\n",
    "## Transaction_ID.csv and Customer_ID.csv\n",
    "- Relationship: Many-to-One\n",
    "- Customer_ID is the primary key in Customer_ID.csv and a foreign key in Transaction_ID.csv. We can join these files using Customer_ID.\n",
    "\n",
    "## Cab_Data.csv and City.csv\n",
    "- Relationship: Many-to-One\n",
    "- City is the primary key in City.csv and a common field in Cab_Data.csv. We can join these files using City.\n",
    "\n",
    "## There are no files to append."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c9136-f338-40c9-8a52-08c1b396580d",
   "metadata": {},
   "source": [
    "# Create master data\n",
    "\n",
    "Apply joins described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee0c2f69-7a16-4b2d-b6f2-521961f00d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined with Customer_ID:  359392 records\n",
      "Joined with City data:  359392 records\n",
      "Master Data Preview:\n",
      "   Transaction ID  Date of Travel   Company        City  KM Travelled  \\\n",
      "0        10000011           42377  Pink Cab  ATLANTA GA         30.45   \n",
      "1        10000012           42375  Pink Cab  ATLANTA GA         28.62   \n",
      "2        10000013           42371  Pink Cab  ATLANTA GA          9.04   \n",
      "3        10000014           42376  Pink Cab  ATLANTA GA         33.17   \n",
      "4        10000015           42372  Pink Cab  ATLANTA GA          8.73   \n",
      "\n",
      "   Price Charged  Cost of Trip  Customer ID Payment_Mode Gender  Age  \\\n",
      "0         370.95       313.635        29290         Card   Male   28   \n",
      "1         358.52       334.854        27703         Card   Male   27   \n",
      "2         125.20        97.632        28712         Cash   Male   53   \n",
      "3         377.40       351.602        28020         Cash   Male   23   \n",
      "4         114.62        97.776        27182         Card   Male   33   \n",
      "\n",
      "   Income (USD/Month) Population     Users  \n",
      "0               10813   814,885    24,701   \n",
      "1                9237   814,885    24,701   \n",
      "2               11242   814,885    24,701   \n",
      "3               23327   814,885    24,701   \n",
      "4                8536   814,885    24,701   \n",
      "Total number of rows in Master Data: 359392\n"
     ]
    }
   ],
   "source": [
    "# Create Master Data\n",
    "\n",
    "# Join cab_transaction_merged with Customer_ID.csv on Customer_ID (Many-to-One)\n",
    "cab_transaction_customer_merged = cab_transaction_merged.merge(customer_data_deduped, on=\"Customer ID\", how=\"inner\")\n",
    "print(\"Joined with Customer_ID: \", len(cab_transaction_customer_merged), \"records\")\n",
    "\n",
    "# Join the resulting data with City.csv on City (Many-to-One)\n",
    "master_data = cab_transaction_customer_merged.merge(city_data, on=\"City\", how=\"inner\")\n",
    "print(\"Joined with City data: \", len(master_data), \"records\")\n",
    "\n",
    "# Display the first few rows of the master dataset\n",
    "print(\"Master Data Preview:\")\n",
    "print(master_data.head())\n",
    "\n",
    "# Final master data structure and count\n",
    "print(\"Total number of rows in Master Data:\", len(master_data))\n",
    "\n",
    "master_data.to_csv(\"DataSets/Master_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210b30d-8ab2-4beb-849b-b5adcfee6a4d",
   "metadata": {},
   "source": [
    "# Field/feature transformations\n",
    "\n",
    "## Cab_Data.csv\n",
    " - Create a new column trnasforming Date_of_Travel from integer to string for improved readability. Keep the original Date_of_Travel for ease of calculations. Also, extract day of the week, month and year.\n",
    " - Calculare Cost per KM dividing Cost per Trip by KM Travelled\n",
    " - Calculate Profit per Trip and Profit Margin Ratio\n",
    " - Split City into City_Name and State\n",
    "\n",
    "## City.csv\n",
    " - Calculare user density by dividing Users by Population\n",
    "\n",
    "## Customer_ID.csv\n",
    " - Categorize users by age group\n",
    " - Categorize by income bracket: low, medium, high\n",
    "\n",
    "## Joins\n",
    " - Count transactions per customer\n",
    " - Calculate customer lifetime value by summing Price Charged across all their trips\n",
    " - Monthly and Yearly Trip Count\n",
    " - Day of the week preference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b9c7486-3183-49b2-88b0-8c90b0c5846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Master Data:\n",
      "   Transaction ID Date of Travel   Company        City  KM Travelled  \\\n",
      "0        10000011            NaT  Pink Cab  ATLANTA GA         30.45   \n",
      "1        10000012            NaT  Pink Cab  ATLANTA GA         28.62   \n",
      "2        10000013            NaT  Pink Cab  ATLANTA GA          9.04   \n",
      "3        10000014            NaT  Pink Cab  ATLANTA GA         33.17   \n",
      "4        10000015            NaT  Pink Cab  ATLANTA GA          8.73   \n",
      "\n",
      "   Price Charged  Cost of Trip  Customer ID Payment_Mode Gender  ...  \\\n",
      "0         370.95       313.635        29290         Card   Male  ...   \n",
      "1         358.52       334.854        27703         Card   Male  ...   \n",
      "2         125.20        97.632        28712         Cash   Male  ...   \n",
      "3         377.40       351.602        28020         Cash   Male  ...   \n",
      "4         114.62        97.776        27182         Card   Male  ...   \n",
      "\n",
      "   City Name  State  User Density  Age Group Income Bracket  \\\n",
      "0    ATLANTA     GA      0.030312      26-35         Medium   \n",
      "1    ATLANTA     GA      0.030312      26-35         Medium   \n",
      "2    ATLANTA     GA      0.030312      46-60         Medium   \n",
      "3    ATLANTA     GA      0.030312      18-25           High   \n",
      "4    ATLANTA     GA      0.030312      26-35         Medium   \n",
      "\n",
      "   Transaction Count  Customer Lifetime Value  Monthly Trip Count  \\\n",
      "0                  3                  1761.70                 NaN   \n",
      "1                  4                  1385.05                 NaN   \n",
      "2                  4                  1521.48                 NaN   \n",
      "3                  4                  1866.39                 NaN   \n",
      "4                  4                  1519.96                 NaN   \n",
      "\n",
      "   Yearly Trip Count  Day of the Week Preference  \n",
      "0                NaN                         NaN  \n",
      "1                NaN                         NaN  \n",
      "2                NaN                         NaN  \n",
      "3                NaN                         NaN  \n",
      "4                NaN                         NaN  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Date Transformations\n",
    "# Convert Date_of_Travel from integer to string and extract day of week, month, and year\n",
    "master_data['Date of Travel'] = master_data['Date of Travel'].astype(str)\n",
    "master_data['Date of Travel'] = pd.to_datetime(master_data['Date of Travel'], errors='coerce', format='%Y%m%d')\n",
    "\n",
    "# Extract day of the week, month, and year\n",
    "master_data['Travel Day'] = master_data['Date of Travel'].dt.day_name()\n",
    "master_data['Travel Month'] = master_data['Date of Travel'].dt.month\n",
    "master_data['Travel Year'] = master_data['Date of Travel'].dt.year\n",
    "\n",
    "# 2. Cost per KM\n",
    "# Calculate Cost per KM by dividing Cost of Trip by KM Travelled\n",
    "master_data['Cost per KM'] = master_data['Cost of Trip'] / master_data['KM Travelled']\n",
    "\n",
    "# 3. Profit per Trip and Profit Margin Ratio\n",
    "# Profit per Trip is Price Charged minus Cost of Trip\n",
    "master_data['Profit per Trip'] = master_data['Price Charged'] - master_data['Cost of Trip']\n",
    "\n",
    "# Profit Margin Ratio is Profit per Trip divided by Price Charged\n",
    "master_data['Profit Margin Ratio'] = master_data['Profit per Trip'] / master_data['Price Charged']\n",
    "\n",
    "# 4. Split City into City_Name and State\n",
    "# Assume City column format is \"CityName State\"\n",
    "master_data[['City Name', 'State']] = master_data['City'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "# 5. User Density\n",
    "# Remove commas and convert Population and Users to integers, then calculate User Density\n",
    "master_data['Population'] = master_data['Population'].str.replace(\",\", \"\").astype(int)\n",
    "master_data['Users'] = master_data['Users'].str.replace(\",\", \"\").astype(int)\n",
    "master_data['User Density'] = master_data['Users'] / master_data['Population']\n",
    "\n",
    "# 6. Age Group Categorization\n",
    "# Define age groups\n",
    "age_bins = [0, 18, 25, 35, 45, 60, 100]\n",
    "age_labels = ['<18', '18-25', '26-35', '36-45', '46-60', '60+']\n",
    "master_data['Age Group'] = pd.cut(master_data['Age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# 7. Income Bracket Categorization\n",
    "# Define income brackets (example thresholds, adjust as needed)\n",
    "income_bins = [0, 5000, 15000, 30000, float('inf')]\n",
    "income_labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "master_data['Income Bracket'] = pd.cut(master_data['Income (USD/Month)'], bins=income_bins, labels=income_labels)\n",
    "\n",
    "# 8. Count Transactions per Customer\n",
    "# Calculate transactions per customer\n",
    "transactions_per_customer = master_data.groupby('Customer ID').size()\n",
    "master_data = master_data.merge(transactions_per_customer.rename('Transaction Count'), on='Customer ID')\n",
    "\n",
    "# 9. Customer Lifetime Value\n",
    "# Calculate CLV by summing Price Charged across all trips for each customer\n",
    "clv = master_data.groupby('Customer ID')['Price Charged'].sum()\n",
    "master_data = master_data.merge(clv.rename('Customer Lifetime Value'), on='Customer ID')\n",
    "\n",
    "# 10. Monthly and Yearly Trip Count\n",
    "# Group by month and year for trip count\n",
    "monthly_trip_count = master_data.groupby(['Travel Year', 'Travel Month']).size().rename('Monthly Trip Count')\n",
    "yearly_trip_count = master_data.groupby('Travel Year').size().rename('Yearly Trip Count')\n",
    "\n",
    "# Merge Monthly and Yearly Trip Count back to master_data\n",
    "master_data = master_data.merge(monthly_trip_count, on=['Travel Year', 'Travel Month'], how='left')\n",
    "master_data = master_data.merge(yearly_trip_count, on='Travel Year', how='left')\n",
    "\n",
    "# 11. Day of the Week Preference\n",
    "# Group by day of the week to count trips per day and identify preferences\n",
    "day_of_week_preference = master_data.groupby('Travel Day').size().rename('Day of the Week Preference')\n",
    "master_data = master_data.merge(day_of_week_preference, on='Travel Day', how='left')\n",
    "\n",
    "# Display transformed master_data\n",
    "print(\"Transformed Master Data:\")\n",
    "print(master_data.head())\n",
    "\n",
    "master_data.to_csv(\"DataSets/Master_Data_Transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc510c3-9df6-4bc1-a202-ac6dbad4aa68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
